{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "model_to_beat = ResNet50(weights='imagenet')\n",
    "# model_to_hat = ResNet50(include_top=False)\n",
    "x, y = np.load('val_x_resnet50.npy'), np.load('val_y.npy') \n",
    "pred = model_to_beat.predict(x)\n",
    "tmp = np.zeros_like(pred)\n",
    "tmp[np.arange(len(pred)), pred.argmax(1)] = 1\n",
    "\n",
    "tmp_y = y.reshape((y.shape[0], 1))\n",
    "tmp_y = OneHotEncoder().fit_transform(tmp_y)\n",
    "\n",
    "print(accuracy_score(tmp_y, tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_n_accuracy(x, y, top=500):\n",
    "    total_correct = 0\n",
    "    for i in range(len(x)):\n",
    "        preds = x[i].argsort()[-top:][::-1]\n",
    "        if y[i] in preds:\n",
    "            total_correct += 1\n",
    "    return total_correct/len(x)\n",
    "top_n_accuracy(pred, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import os\n",
    "import tarfile\n",
    "import pickle\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "path_to_imagenet = '/media/louis/Seagate Backup Plus Drive/Datasets/ImageNet/'\n",
    "def make_validation_set():\n",
    "    val_labels_path = path_to_imagenet + 'ILSVRC2012_validation_ground_truth.txt'\n",
    "    val_labels = open(val_labels_path ,'r').readlines()\n",
    "    val_labels = list(map(lambda x: int(x.strip('\\n')), val_labels[:-1]))\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    val_data_path = path_to_imagenet + 'Validation/'\n",
    "    all_val_data_path = os.listdir(val_data_path)\n",
    "    all_val_data = np.zeros(shape=(len(all_val_data_path), 224, 224, 3), dtype=np.float32)\n",
    "\n",
    "    for i in range(len(all_val_data)):\n",
    "        all_val_data[i] = image.img_to_array(image.load_img(val_data_path + all_val_data_path[i],\n",
    "                                                                        target_size=(224, 224))).astype(np.float32)\n",
    "        all_val_data[i] = preprocess_input(all_val_data[i]).astype(np.float32)\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "    np.save('val_x', all_val_data)\n",
    "    cut_model = ResNet50(include_top=False)\n",
    "    all_val_data = cut_model.predict(all_val_data)\n",
    "    all_val_data = np.squeeze(all_val_data)\n",
    "    np.save('val_ResNet50_x', all_val_data)\n",
    "    np.save('val_y', val_labels)\n",
    "\n",
    "\n",
    "# def make_training_set(cut_model):\n",
    "\n",
    "#     train_data_path = path_to_imagenet + 'Training/'\n",
    "#     all_train_data = os.listdir(train_data_path)\n",
    "#     train_data = []\n",
    "#     train_val = []\n",
    "#     for i in range(len(all_train_data)):\n",
    "#         class_images = os.listdir(train_data_path + all_train_data[i])\n",
    "#         tmp_train_data = []\n",
    "#         for images in class_images:\n",
    "#             tmp_train_data.append(image.img_to_array(\n",
    "#                 image.load_img(train_data_path + all_train_data[i] + '/' + images, \n",
    "#                                      target_size=(224, 224))).astype(np.float32))\n",
    "#             train_val.append(i)\n",
    "#         tmp_train_data = np.asarray(tmp_train_data) \n",
    "#         tmp_train_data = preprocess_input(tmp_train_data).astype(np.float32)\n",
    "#         tmp_train_data = cut_model.predict(tmp_train_data)\n",
    "#         tmp_train_data = np.squeeze(tmp_train_data)\n",
    "#         train_data.append(tmp_train_data)\n",
    "#         if i % 10 == 0:\n",
    "#             print(i)\n",
    "#     train_data = np.concatenate(train_data)\n",
    "#     print(train_data.shape)\n",
    "#     np.save('train_ResNet50_x', train_data)\n",
    "#     train_val = np.asarray(train_val)\n",
    "#     np.save('train_ResNet50_y', train_val)\n",
    "        \n",
    "        \n",
    "make_validation_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256233, 2048) (50000, 2048) (256233,) (50000,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from skopt.space import Real, Integer\n",
    "from skopt.utils import use_named_args\n",
    "from skopt import gp_minimize\n",
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "\n",
    "train_x, train_y = np.load('train_ResNet50_x.npy'), np.load('train_ResNet50_y.npy')\n",
    "train_x, train_y = unison_shuffled_copies(train_x, train_y)\n",
    "val_x, val_y = np.load('val_ResNet50_x.npy'), np.load('val_y.npy')\n",
    "train_x, train_y = train_x[:len(train_x)//5], train_y[:len(train_y)//5]\n",
    "print(train_x.shape, val_x.shape, train_y.shape, val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [Integer(2, 200, name='n_estimators'),\n",
    "         Real(10e-5, 10e-1, \"log-uniform\", name='learning_rate'),\n",
    "         Integer(2, 20, name='num_leaves'),\n",
    "         Real(10e-10, 10e-1, name='reg_alpha'),\n",
    "         Real(10e-10, 10e-1, name='reg_lambda')]\n",
    "\n",
    "clf = LGBMClassifier(verbose=-1)\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    print(params)\n",
    "    clf.set_params(**params)\n",
    "    return -np.mean(cross_val_score(clf, train_x, train_y, cv=2,\n",
    "                                    scoring='neg_log_loss', verbose=True))\n",
    "\n",
    "res_gp = gp_minimize(objective, space, n_calls=10, random_state=42, verbose=True)\n",
    "print(res_gp.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_clf = LGBMClassifer(n_estimators=res_gp.x[0], learning_rate=res_gp.x[1], num_leaves=res_gp.x[2],\n",
    "#                                reg_alpha=res_gp.x[3], reg_lambda=res_gp.x[4])\n",
    "best_clf = LGBMClassifier()\n",
    "best_clf.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(train_x)\n",
    "tmp_y = val_y.reshape((val_y.shape[0], 1))\n",
    "tmp_y = OneHotEncoder().fit_transform(tmp_y)\n",
    "\n",
    "print(accuracy_score(tmp_y, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
